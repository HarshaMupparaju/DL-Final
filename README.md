# Weakly Supervised Local-Global Relation Network for Facial Expression Recognition #

The framework described in the paper has 2 stages, stage 1 consists of the AMG(Attention Map Generator) as shown in the figure. The existing Facial Expression Datasets do not have eyes and mouth regions highlighted in the images of the dataset , so making a dataset which has these annotations is also a very time consuming task. In order to overcome this issue, the paper proposes an AMG(Attention map generator) which consists of a densenet. The AMG acts on Celeb-A dataset, which has a csv file consisting of the attributes of the images. We use a densenet to identify the eyes and the mouth regions in a Weakly Supervised learning algorithm proposed in the paper. Once the model learns , we then freeze the weights and transfer these weights to our facial expression dataset( the paper uses CK+, we planned to use FER 2013). In the second stage of the framework there are two branches as shown, the paper uses LFE(Local Feature Extraction) and GFE(Global Feature Extraction) but doesnâ€™t specify the implementation details of LFE and GFE, we used SIFT for LFE and HOG for GFE. The outputs of the first stage and LFE Feature maps are element-wise multiplied and connected to a fully connected layer and loss function is calculated based on whether the two images from the two different branches are of the same expression or not. Similarly, the outputs of the GFE are connected to a fully connected layer and a global sensitive contrastive loss is calculated . The element wise multiplied feature maps and attention maps of eyes and mouth and the GFE feature map are then inputted into the RRU(Relational Reasoning Unit) , which calculates the weights for classification and calculates the total loss of the framework. The output of the RRU is then fed to the classifier, which gives us the expression of the image.

### Preferably run on Google Colab after uploading kaggle.json ###

